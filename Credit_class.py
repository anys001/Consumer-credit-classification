# -*- coding: utf-8 -*-
"""Final_Bankpr_NWUPD.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XdrfwBSfGDNDlmOlnR1lQuotZxrcwyW7

# About project

### We need to build a classification model based on the limited dataset for propensity to the product "**Consumer Credit**".
<br>

***Datasets***:<br>
`Clients` -- Clients<br>
`Transactions` -- Transactions<br>
<br>

***Description***:<br>

**Clients**<br>
`client_id` - Client ID<br>
`age` - Age<br>
`gender_code` - Gender<br>
`directory` - City<br>
`aMRG_eop` - Mortgage debt balance<br>
`aCSH_eop` - Consumer loan debt balance<br>
`aCRD_eop` - Credit card debt balance<br>
`pCUR_eop` - Current account balance<br>
`pCRD_eop` - Card account balance<br>
`pSAV_eop` - Savings account balance<br>
`pDEP_eop` - Deposit account balance<br>
`sWork_S` - Monthly salary<br>
`tPOS_S` - POS transaction amount<br>
<br>
**Transactions**<br>
`client_id` - Client ID<br>
`TRANSACTION_DT` - Transaction date<br>
`MCC_KIND_CD` - MCC type<br>
`MCC_CD` - MCC code<br>
`CARD_AMOUNT_EQV_CBR` - Transaction amount in Russian rubles<br>

# Installations
"""

!pip install PhiK

!pip install catboost

"""## Service code"""

import matplotlib.font_manager as fm
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sn
from matplotlib.collections import QuadMesh


def get_new_fig(fn, figsize=[9, 9]):
    """Init graphics"""
    fig1 = plt.figure(fn, figsize)
    ax1 = fig1.gca()  # Get Current Axis
    ax1.cla()  # clear existing plot
    return fig1, ax1


def configcell_text_and_colors(
    array_df, lin, col, oText, facecolors, posi, fz, fmt, show_null_values=0
):
    """
    config cell text and colors
    and return text elements to add and to dell
    @TODO: use fmt
    """
    text_add = []
    text_del = []
    cell_val = array_df[lin][col]
    tot_all = array_df[-1][-1]
    per = (float(cell_val) / tot_all) * 100
    curr_column = array_df[:, col]
    ccl = len(curr_column)

    # last line  and/or last column
    if (col == (ccl - 1)) or (lin == (ccl - 1)):
        # tots and percents
        if cell_val != 0:
            if (col == ccl - 1) and (lin == ccl - 1):
                tot_rig = 0
                for i in range(array_df.shape[0] - 1):
                    tot_rig += array_df[i][i]
                per_ok = (float(tot_rig) / cell_val) * 100
            elif col == ccl - 1:
                tot_rig = array_df[lin][lin]
                per_ok = (float(tot_rig) / cell_val) * 100
            elif lin == ccl - 1:
                tot_rig = array_df[col][col]
                per_ok = (float(tot_rig) / cell_val) * 100
            per_err = 100 - per_ok
        else:
            per_ok = per_err = 0

        per_ok_s = ["%.2f%%" % (per_ok), "100%"][per_ok == 100]

        # text to DEL
        text_del.append(oText)

        # text to ADD
        font_prop = fm.FontProperties(weight="bold", size=fz)
        text_kwargs = dict(
            color="w",
            ha="center",
            va="center",
            gid="sum",
            fontproperties=font_prop,
        )
        lis_txt = ["%d" % (cell_val), per_ok_s, "%.2f%%" % (per_err)]
        lis_kwa = [text_kwargs]
        dic = text_kwargs.copy()
        dic["color"] = "g"
        lis_kwa.append(dic)
        dic = text_kwargs.copy()
        dic["color"] = "r"
        lis_kwa.append(dic)
        lis_pos = [
            (oText._x, oText._y - 0.3),
            (oText._x, oText._y),
            (oText._x, oText._y + 0.3),
        ]
        for i in range(len(lis_txt)):
            newText = dict(
                x=lis_pos[i][0],
                y=lis_pos[i][1],
                text=lis_txt[i],
                kw=lis_kwa[i],
            )
            text_add.append(newText)

        # set background color for sum cells (last line and last column)
        carr = [0.27, 0.30, 0.27, 1.0]
        if (col == ccl - 1) and (lin == ccl - 1):
            carr = [0.17, 0.20, 0.17, 1.0]
        facecolors[posi] = carr

    else:
        if per > 0:
            txt = "%s\n%.2f%%" % (cell_val, per)
        else:
            if show_null_values == 0:
                txt = ""
            elif show_null_values == 1:
                txt = "0"
            else:
                txt = "0\n0.0%"
        oText.set_text(txt)

        # main diagonal
        if col == lin:
            # set color of the textin the diagonal to white
            oText.set_color("w")
            # set background color in the diagonal to blue
            facecolors[posi] = [0.35, 0.8, 0.55, 1.0]
        else:
            oText.set_color("r")

    return text_add, text_del


def insert_totals(df_cm):
    """insert total column and line (the last ones)"""
    sum_col = []
    for c in df_cm.columns:
        sum_col.append(df_cm[c].sum())
    sum_lin = []
    for item_line in df_cm.iterrows():
        sum_lin.append(item_line[1].sum())
    df_cm["sum_lin"] = sum_lin
    sum_col.append(np.sum(sum_lin))
    df_cm.loc["sum_col"] = sum_col

def pp_matrix(
    df_cm,
    annot=True,
    cmap="Oranges",
    fmt=".2f",
    fz=11,
    lw=0.5,
    cbar=False,
    figsize=[8, 8],
    show_null_values=0,
    pred_val_axis="y",
    title="Confusion Matrix"
):
    """
    print conf matrix with default layout (like matlab)
    params:
      df_cm          dataframe (pandas) without totals
      annot          print text in each cell
      cmap           Oranges,Oranges_r,YlGnBu,Blues,RdBu, ... see:
      fz             fontsize
      lw             linewidth
      pred_val_axis  where to show the prediction values (x or y axis)
                      'col' or 'x': show predicted values in columns (x axis) instead lines
                      'lin' or 'y': show predicted values in lines   (y axis)
    """
    if pred_val_axis in ("col", "x"):
        xlbl = "Predicted"
        ylbl = "Actual"
    else:
        xlbl = "Actual"
        ylbl = "Predicted"
        df_cm = df_cm.T

    # create "Total" column
    insert_totals(df_cm)

    # this is for print allways in the same window
    fig, ax1 = get_new_fig("Conf matrix default", figsize)

    ax = sn.heatmap(
        df_cm,
        annot=annot,
        annot_kws={"size": fz},
        linewidths=lw,
        ax=ax1,
        cbar=cbar,
        cmap=cmap,
        linecolor="w",
        fmt=fmt,
    )

    # set ticklabels rotation
    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, fontsize=10)
    ax.set_yticklabels(ax.get_yticklabels(), rotation=25, fontsize=10)

    # Turn off all the ticks
    for t in ax.xaxis.get_major_ticks():
        t.tick1On = False
        t.tick2On = False
    for t in ax.yaxis.get_major_ticks():
        t.tick1On = False
        t.tick2On = False

    # face colors list
    quadmesh = ax.findobj(QuadMesh)[0]
    facecolors = quadmesh.get_facecolors()

    # iter in text elements
    array_df = np.array(df_cm.to_records(index=False).tolist())
    text_add = []
    text_del = []
    posi = -1  # from left to right, bottom to top.
    for t in ax.collections[0].axes.texts:  # ax.texts:
        pos = np.array(t.get_position()) - [0.5, 0.5]
        lin = int(pos[1])
        col = int(pos[0])
        posi += 1

        # set text
        txt_res = configcell_text_and_colors(
            array_df, lin, col, t, facecolors, posi, fz, fmt, show_null_values
        )

        text_add.extend(txt_res[0])
        text_del.extend(txt_res[1])

    # remove the old ones
    for item in text_del:
        item.remove()
    # append the new ones
    for item in text_add:
        ax.text(item["x"], item["y"], item["text"], **item["kw"])

    # titles and legends
    ax.set_title(title)
    ax.set_xlabel(xlbl)
    ax.set_ylabel(ylbl)
    plt.tight_layout()  # set layout slim
    plt.show()


def pp_matrix_from_data(
    y_test,
    predictions,
    columns=None,
    annot=True,
    cmap="Oranges",
    fmt=".2f",
    fz=11,
    lw=0.5,
    cbar=False,
    figsize=[8, 8],
    show_null_values=0,
    pred_val_axis="lin",
    title="Confusion Matrix"
):
    """
    plot confusion matrix function with y_test (actual values) and predictions (predic),
    whitout a confusion matrix yet
    """
    from pandas import DataFrame
    from sklearn.metrics import confusion_matrix

    # data
    if not columns:
        from string import ascii_uppercase

        columns = [
            "class %s" % (i)
            for i in list(ascii_uppercase)[0 : len(np.unique(y_test))]
        ]

    confm = confusion_matrix(y_test, predictions)
    df_cm = DataFrame(confm, index=columns, columns=columns)
    pp_matrix(
        df_cm,
        fz=fz,
        cmap=cmap,
        figsize=figsize,
        show_null_values=show_null_values,
        pred_val_axis=pred_val_axis,
        title=title
    )
def plot_CM(model, x, y_true, target_names=['Class 1', 'Class 2', 'Class 3', 'Class 4'], title="Dataset", figsize=[5, 5]):
    # confusion matrix
    y_pred = np.argmax(model.predict_proba(x), axis=1)

    pp_matrix_from_data(y_test=y_true, predictions=y_pred, columns=target_names, cbar=False, figsize=figsize, cmap=sns.light_palette("seagreen", as_cmap=True), fz=10,  pred_val_axis="x", title=title)
    return y_pred

from sklearn.metrics import roc_curve, auc, f1_score
from sklearn.preprocessing import label_binarize
import numpy as np
import plotly.graph_objs as go

def plot_multiclass_roc(Ytrue, Yprob, labels=['class 0', 'class 1', 'class 2', 'class 3'], figsize=(850, 700)):
    n_classes = Yprob.shape[1]
    Ypred = np.argmax(Yprob, axis=1)

    # Бинаризация истинных меток классов
    # Ytrue_bin = label_binarize(Ytrue, classes=np.arange(n_classes))
    Ytrue_bin = pd.get_dummies(Ytrue.reshape(-1)).values

    # Структуры данных для хранения результатов
    fpr = dict()
    tpr = dict()
    roc_auc = dict()
    fig = go.Figure()

    # Вычисление FPR, TPR и AUC для каждого класса
    for i in range(n_classes):
        fpr[i], tpr[i], thresholds = roc_curve(Ytrue_bin[:, i], Yprob[:, i])
        roc_auc[i] = auc(fpr[i], tpr[i])
        fig.add_trace(go.Scatter(x=fpr[i], y=tpr[i], mode='lines', name=f'ROC curve "{labels[i]}"'))
        fig.add_trace(go.Scatter(x=fpr[i], y=thresholds, mode='lines', name=f'Threshold "{labels[i]}"', line=dict(dash='dash')))

    # Вычисление микро-усредненного AUC
    fpr["micro"], tpr["micro"], _ = roc_curve(Ytrue_bin.ravel(), Yprob.ravel())
    roc_auc["micro"] = auc(fpr["micro"], tpr["micro"])

    # Вычисление макро-усредненного AUC
    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))
    mean_tpr = np.zeros_like(all_fpr)
    for i in range(n_classes):
        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])
    mean_tpr /= n_classes
    fpr["macro"] = all_fpr
    tpr["macro"] = mean_tpr
    roc_auc["macro"] = auc(fpr["macro"], tpr["macro"])

    # Вычисление F1-score (микро, макро и взвешенного)
    f1_micro = f1_score(Ytrue, Ypred, average='micro')
    f1_macro = f1_score(Ytrue, Ypred, average='macro')
    f1_weighted = f1_score(Ytrue, Ypred, average='weighted')

    # Визуализация с Plotly
    fig.update_layout(
        title="ROC Curves and Thresholds for Multiclass",
        xaxis_title="False Positive Rate (FPR)",
        yaxis_title="True Positive Rate (TPR) / Probability Threshold",
        yaxis=dict(range=[0, 1]),
        xaxis=dict(scaleanchor="y", scaleratio=1),
        width=figsize[0],
        height=figsize[1]
    )

    fig.show()

    return roc_auc, {"f1_micro": f1_micro, "f1_macro": f1_macro, "f1_weighted": f1_weighted}

"""# Data loading"""

import gdown

def download_from_google(id, save_as):
    gdown.download(f"https://drive.google.com/uc?id={id}", output=save_as, quiet=True)

download_from_google('1NSNd1GGbplxC36IJ6hfXvvo398jz-knV', '/content/Transactions.csv')
download_from_google('1KS3NIupNHli6rnj7zz5YgnEZCbf7Okee', '/content/Clients.csv')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import phik
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
from sklearn.preprocessing import MinMaxScaler

# reading datas
clients = pd.read_csv("/content/Clients.csv", delimiter=';')
transactions = pd.read_csv('/content/Transactions.csv', delimiter=';')

# Importing data_table module from google.colab for dataframe formatting
from google.colab import data_table

# Importing DataTable class from google.colab.data_table for enhanced data representation
from google.colab.data_table import DataTable

# Enabling enhanced dataframe formatting using Google Colab's data_table
data_table.enable_dataframe_formatter()

# Setting the limit for the number of columns to display in a dataframe
COLS_LIMIT = 200

# Configuring pandas to display up to 50 columns in a dataframe
pd.set_option('display.max_columns', COLS_LIMIT)

# Setting the maximum number of columns to display in DataTable to 50
DataTable.max_columns = COLS_LIMIT

"""# Data preprocessing

## Clients
"""

# Convert age to int
clients['age'] = clients['age'].astype(int)

# Replace commas with periods and convert to float
clients['aMRG_eop'] = clients['aMRG_eop'].str.replace(',', '.').astype(float)
clients['aCSH_eop'] = clients['aCSH_eop'].str.replace(',', '.').astype(float)

clients['aCRD_eop'] = clients['aCRD_eop'].str.replace(',', '.').astype(float)
clients['pCUR_eop'] = clients['pCUR_eop'].str.replace(',', '.').astype(float)

clients['pCRD_eop'] = clients['pCRD_eop'].str.replace(',', '.').astype(float)
clients['pSAV_eop'] = clients['pSAV_eop'].str.replace(',', '.').astype(float)

clients['pDEP_eop'] = clients['pDEP_eop'].str.replace(',', '.').astype(float)
clients['sWork_S'] = clients['sWork_S'].str.replace(',', '.').astype(float)
clients['tPOS_S'] = clients['tPOS_S'].str.replace(',', '.').astype(float)

num_obscl = clients.shape[0]
print(f"Number of Observations: {num_obscl}")
clients

# Mapping gender_code to gnd_num
clients['gnd_num'] = clients['gender_code'].apply(lambda x: 2 if x == 'Ж' else 1 if x == 'М' else None)

# Dictionary to map the values
dir_mapping = {
    'Москва': 1,
    'Санкт-Петербург': 2,
    'Нижний Новгород': 3,
    'Казань': 4,
    'Томск': 5,
    'Ростов-на-Дону': 6,
    'Астрахань': 7,
    'Краснодар': 8,
    'Ставрополь': 9,
    'Тула': 10,
    'Воронеж': 11,
    'Новый Уренгой': 12,
    'Южно-Сахалинск': 13,
    'Югорск': 14,
    'Красноярск': 15,
    'Калининград': 16,
    'Пермь': 17,
    'Волгоград': 18,
    'ДРБЦР': 19,
    'Сургут': 20,
    'Екатеринбург': 21,
    'Благовещенск': 22,
    'Владивосток': 23,
    'Центральный': 24,
    'Новосибирск': 25,
    'Тюмень': 26,
    'Уфа': 27,
    'Самара': 28,
    'Кемерово': 29,
    'Якутск': 30,
    'Хабаровск': 31
}

# Mapping directory to dir_num
clients['dir_num'] = clients['directory'].map(dir_mapping)

clients.info()

sns.set(style="whitegrid")
g = sns.PairGrid(clients)
g.map(sns.scatterplot, color='skyblue')
plt.show()

# A distribution plot for Age
sns.set(style="whitegrid")
plt.figure(figsize=(10, 6))
sns.histplot(clients['age'], kde=True, bins=20, color='skyblue')
plt.title('Distribution of Age in Clients Dataset')
plt.xlabel('Age')
plt.ylabel('Count')
plt.show()

# A distribution plot for directory
sns.set(style="whitegrid")
plt.figure(figsize=(12, 8))
ax = sns.histplot(clients['directory'], kde=True, bins=20, color='skyblue')
plt.xticks(rotation=90)
plt.title('Distribution of Cities in Clients Dataset')
plt.xlabel('City')
plt.ylabel('Count')
plt.show()

# A distribution plot for gender
sns.set(style="whitegrid")
plt.figure(figsize=(10, 6))
sns.histplot(clients['gender_code'], kde=True, bins=2, color='skyblue')
plt.title('Distribution of Gender in Clients Dataset')
plt.xlabel('Gender')
plt.ylabel('Count')
plt.ylim(0, 800)  # Set the y-axis limits
plt.show()

"""## Transactions"""

# Convert TRANSACTION_DT to datetime
transactions['TRANSACTION_DT'] = pd.to_datetime(transactions['TRANSACTION_DT'])

# Convert MCC_CD to float
transactions['MCC_CD'] = transactions['MCC_CD'].astype(float)

# Replace commas with periods and convert CARD_AMOUNT_EQV_CBR to float
transactions['CARD_AMOUNT_EQV_CBR'] = transactions['CARD_AMOUNT_EQV_CBR'].str.replace(',', '.').astype(float)

num_obstr = transactions.shape[0]
print(f"Number of Observations: {num_obstr}")
transactions

sns.set(style="whitegrid")
g = sns.PairGrid(transactions)
g.map(sns.scatterplot, color='skyblue')
plt.show()

# Dictionary to map the values
kind_mapping = {
    'Авиалинии, авиакомпании': 1,
    'Автомобили и транспортные средства': 2,
    'Аренда автомобилей': 3,
    'Бизнес услуги': 4,
    'Государственные услуги': 5,
    'Коммунальные и кабельные услуги': 6,
    'Контрактные услуги': 7,
    'Личные услуги': 8,
    'Магазины одежды': 9,
    'Оптовые поставщики и производители': 10,
    'Отели и мотели': 11,
    'Продажи по почте/телефону': 12,
    'Профессиональные услуги': 13,
    'Развлечения': 14,
    'Различные магазины': 15,
    'Розничные магазины': 16,
    'Строительные магазины': 17,
    'Транспортные услуги': 18,
    'Финансовые услуги': 19,
    'Членские взносы': 20,
}

transactions['trkind_num'] = transactions['MCC_KIND_CD'].map(kind_mapping)

transactions.info()

# Find missing values
transactions[transactions.isna().any(axis=1)]

"""В данной таблице есть пропуски. Отобразим их:"""

# checking MCC_CD
desired_mcc_cd = 780.0

# using indexing
transactions[transactions['MCC_CD'] == desired_mcc_cd]

# Check for missing values
missing_values = transactions.isnull().sum()
print(missing_values)
# Drop rows with missing values
transactions = transactions.dropna()

# Check the uniqueness of combinations of MCC_KIND_CD and MCC_CD
uniq_comb = transactions.groupby(['MCC_KIND_CD', 'MCC_CD']).size().reset_index(name='count')
nuniq_comb = uniq_comb[uniq_comb['count'] > 1]

# Print the non-unique combinations
print("Non-unique combinations of MCC_KIND_CD and MCC_CD:")
print(nuniq_comb)
#As we could see here, MCC_KIND_CD and MCC_CD are not in one to one correspondance, so we need to keep both of them

# A distribution plot for Age
sns.set(style="whitegrid")
plt.figure(figsize=(10, 6))
sns.histplot(transactions['MCC_KIND_CD'], kde=True, bins=20, color='skyblue')
plt.xticks(rotation=90)
plt.title('Distribution of transactions in transactions Dataset')
plt.xlabel('transaction')
plt.ylabel('Count')
plt.show()

"""## Data merging"""

tr_summary = transactions.groupby('client_id')['CARD_AMOUNT_EQV_CBR'].agg(['mean', 'count', 'min', 'max', 'median', lambda x: x.quantile(0.25), lambda x: x.quantile(0.75)]).reset_index()

# Renameing the columns
tr_summary.columns = ['client_id', 'avg_tr', 'tr_count', 'min_tr', 'max_tr', 'median_tr', 'q1_tr', 'q3_tr']

# One to one merge with clients dataset
df_1mrg = pd.merge(clients, tr_summary, on='client_id', how='left')

display(df_1mrg)

"""# Features engineering

We are using aCSH_eop for creating target variable. aCSH_eop is showing loan balance, but here we consider, that if aCSH_eop = 0, then client have no Consumer Credit(of course client could take credit and then pay it and in that case loan would be 0, but in this dataset we do not have any other variable, which shows more concreat information about consumer credit).
"""

df_kind = transactions.pivot_table(index='client_id', columns='MCC_KIND_CD', values='CARD_AMOUNT_EQV_CBR', aggfunc='sum', fill_value=0).reset_index()


# Rename the columns
#df_transposed.columns = ['client_id'] + [kind_mapping.get(col, col) for col in df_transposed.columns[1:]]
column_names = ['client_id'] + ['kind_' + str(kind_mapping[col]) if col in kind_mapping else col for col in df_kind.columns[1:]]
df_kind.columns = column_names

# Convert to binary version
#for col in df_transposed.columns[1:]:
#    df_transposed[col] = (df_transposed[col] > 0).astype(int)

#df_kind = transactions[['client_id']].merge(df_kind, on='client_id', how='left').fillna(0)

# Print the transposed dataset
print(len(df_kind))
display(df_kind)

df_1mrg = pd.merge(df_1mrg, df_kind, on='client_id', how='left')
display(df_1mrg)

df_1mrg.columns

age_values = df_1mrg['age'].values.reshape(-1, 1)

#grouping age
bins = [18, 25, 35, 45, 55, 65, 100]
labels = ['18-25', '26-35', '36-45', '46-55', '56-65', '66+']
df_1mrg['age_group'] = pd.cut(df_1mrg['age'], bins=bins, labels=labels, right=False)
#display(df_merged)

"""## Checking dependencies in dataset"""

selected_columns = ['aMRG_eop', 'aCRD_eop', 'pCUR_eop', 'pCRD_eop', 'pSAV_eop', 'pDEP_eop', 'sWork_S', 'tPOS_S', 'avg_tr']
corr = df_1mrg[selected_columns].corr()

# Create the heatmap
plt.figure(figsize=(12, 10), dpi=80)
heatmap = sns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns, center=0, annot=True)
plt.show()
heatmap.get_figure().savefig("corr.png")

matrix_p = df_1mrg[selected_columns].phik_matrix(interval_cols=selected_columns)
display(matrix_p)

plt.figure(figsize = (12,10), dpi=80)
sns.heatmap(matrix_p,
           vmax=1,
           square=True,
           annot=True,
           cmap='coolwarm',
           center=0,
           annot_kws={'size':12})

# Set the style
sns.set(style="whitegrid")

# Create the catplot with the specified style
plt.figure(figsize=(10, 6))
sns.catplot(data=df_1mrg, x="aCSH_eop", y="gender_code", kind="box", palette="pastel")
plt.title('Boxplot of Consumer Loan Debt Balance by Gender')
plt.xlabel('Consumer Loan Debt Balance')
plt.ylabel('Gender')
plt.show()

selc_columns = ['aMRG_eop', 'aCRD_eop', 'pCUR_eop', 'pCRD_eop', 'pSAV_eop', 'pDEP_eop', 'sWork_S','aCSH_eop', 'tPOS_S', 'gender_code']
sns.pairplot(df_1mrg[selc_columns], hue="gender_code", height=2.5, palette="pastel")

# A distribution plot for age and consumer credit
sns.set(style="whitegrid")
plt.figure(figsize=(10, 6))
sns.scatterplot(data = df_1mrg, x = clients['age'], y =clients['aCSH_eop'], color='skyblue')
plt.title('Scatterplot of Loan Debt Balance by Age')
plt.xlabel('Age')
plt.ylabel('consumer credit')
plt.show()

sns.set(style="whitegrid")
plt.figure(figsize=(10, 6))
sns.displot(df_1mrg, x="aCSH_eop", hue="age_group", kind="kde", palette="pastel")
plt.title('Kernel Density Estimate of Consumer Loan Debt Balance by Age Category')
plt.xlabel('Consumer Loan Debt Balance')
plt.ylabel('Density')
plt.show()

sns.set(style="whitegrid")
plt.figure(figsize=(10, 6))
sns.catplot(data=df_1mrg, x="age_group", y="aCSH_eop", hue = "gender_code", kind="swarm", palette="pastel")
plt.title('Consumer Loan Debt Balance by Age Category and Gender')
plt.xlabel('Age group')
plt.ylabel('Consumer Loan Debt Balance')
plt.show()

# A distribution plot for directory
sns.set(style="whitegrid")
plt.figure(figsize=(12, 8))
ax = sns.catplot(data=df_1mrg, x="directory", y="aCSH_eop", color='skyblue')
ax.set_xticklabels(rotation=90)
plt.title('Consumer Loan Debt Balance by Location')
plt.xlabel('City')
plt.ylabel('Consumer Loan Balance')
plt.tight_layout()
plt.show()

# A distribution plot for age and consumer credit
sns.set(style="whitegrid")
plt.figure(figsize=(10, 6))
sns.scatterplot(data = df_1mrg, x = clients['sWork_S'], y =clients['aCSH_eop'], color='skyblue')
plt.title('Consumer Loan Debt Balance by Monthly salary')
plt.xlabel('Monthly salary')
plt.ylabel('Consumer credit')
plt.show()

# A distribution plot for age and consumer credit
sns.set(style="whitegrid")
plt.figure(figsize=(10, 6))
sns.scatterplot(data = df_1mrg, x = clients['pCUR_eop'], y =clients['aCSH_eop'], color='skyblue')
plt.title('Consumer Loan Debt Balance by Current account balance')
plt.xlabel('Current account balance')
plt.ylabel('Consumer credit')
plt.show()

sns.set(style="whitegrid")
plt.figure(figsize=(10, 6))
sns.relplot(data=df_1mrg, x="aCRD_eop", y="aCSH_eop", hue="gender_code", palette="pastel")
plt.title('Consumer Loan Debt Balance by Credit card debt balance, showing by gender')
plt.xlabel('Credit card debt balance')
plt.ylabel('Consumer credit')
plt.show()

sns.set(style="whitegrid")
plt.figure(figsize=(10, 6))
sns.relplot(data=df_1mrg, x="pSAV_eop", y="aCSH_eop", hue="gender_code", palette="pastel")
plt.title('Consumer Loan Debt Balance by Savings account balance, showing by gender')
plt.xlabel('Savings account balance')
plt.ylabel('Consumer credit')
plt.show()

sns.set(style="whitegrid")
plt.figure(figsize=(10, 6))
sns.relplot(data=df_1mrg, x="pDEP_eop", y="aCSH_eop", hue="gender_code", palette="pastel")
plt.title('Consumer Loan Debt Balance by Deposit account balance, showing by gender')
plt.xlabel('Deposit account balance')
plt.ylabel('Consumer credit')
plt.show()

sns.set(style="whitegrid")
plt.figure(figsize=(10, 6))
sns.relplot(data=df_1mrg, x="tPOS_S", y="aCSH_eop", hue="gender_code", palette="pastel")
plt.title('Consumer Loan Debt Balance by POS transaction amount, showing by gender')
plt.xlabel('POS transaction amount')
plt.ylabel('Consumer credit')
plt.show()

# Setting threshold
threshold = 0.0

# Creating target variable
df_1mrg['Target'] = (df_1mrg['aCSH_eop'] > threshold).astype('int8')
df_1mrg.drop(columns=['aCSH_eop'])

selc_columns = ['aMRG_eop', 'aCRD_eop', 'pCUR_eop', 'pCRD_eop', 'pSAV_eop', 'pDEP_eop', 'sWork_S', 'tPOS_S', 'Target']
sns.pairplot(df_1mrg[selc_columns], hue="Target", height=2.5, palette="pastel")

def transform_get_fitted_StandardScaler(df, columns):
    scaler_std = StandardScaler()
    return scaler_std.fit_transform(df[columns]), scaler_std

def transform_get_fitted_MinMaxScaler(df, columns):
    scaler_mnx = MinMaxScaler()
    return scaler_mnx.fit_transform(df[columns]), scaler_mnx

# One-Hot encoding for directory
print(df_1mrg['directory'].nunique())
df_1mrg['directory'].unique()
df_1mrg = pd.get_dummies(df_1mrg, columns=['dir_num', ])
df_1mrg

df_1mrg.shape

df_1mrg.columns

df_1mrg['gender'] = df_1mrg['gender_code']
df_1mrg['gender_code'] = df_1mrg['gender_code'].astype('category').cat.codes

df_1mrg['age_group']

df_1mrg['age_code'] = df_1mrg['age_group'].cat.codes

"""### Visualizing categorical features by target"""

def plot_stacked_bar(data, category, target, ax):
    # Calculate the count of values for each category
    counts = data.groupby([category, target]).size().unstack()

    # If there are N/D values, move them to the end for better visualization
    if 'N/D' in counts.index:
        n_d = counts.loc['N/D']
        counts = counts.drop('N/D')
        counts.loc['N/D'] = n_d

    # Normalize the data so that the sum for each category equals 1
    counts = counts.T.div(counts.T.sum()).T

    # Plot stacked bars
    bars = counts.plot(kind='bar', stacked=True, ax=ax, color=['#1f77b4', '#d62728'])

    # Add horizontal dashed lines
    for yval in ax.get_yticks():
        ax.axhline(y=yval, linestyle='--', color='grey', alpha=0.7)

    ax.set_title(f'Stacked Bar Chart of {category}')
    ax.set_ylabel('Proportion of Customers')
    ax.set_xlabel(category)
    ax.legend(title=target, loc='upper right')

    return bars

def draw_df_per_target(df, target, categorical_columns, rows=5, cols=3, figsize=(15, 22)):
    # Draw stacked bars for each categorical column with valid data
    fig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=figsize)
    axes = axes.flatten()  # Convert the array of axes into a one-dimensional array

    # Plotting graphs for each categorical feature
    for ax, category in zip(axes, categorical_columns):
        plot_stacked_bar(df, category, target, ax)

    # Remove excess axes, if any
    for i in range(len(categorical_columns), len(axes)):
        fig.delaxes(axes[i])

    # Adjust the spacing between subplots
    plt.tight_layout()
    plt.show()

draw_df_per_target(df_1mrg, 'Target', ['gender', 'age_group', 'directory'], figsize=(14, 20), cols=1)

"""# Machine learning/Model part"""

FEATURES = df_1mrg.drop(columns=['client_id', 'directory', 'aCSH_eop', 'Target', 'gender', 'age_group']).columns.tolist()

df_1mrg[FEATURES]

from sklearn.preprocessing import OneHotEncoder

Y = df_1mrg['Target']

from sklearn.model_selection import train_test_split

train_ids, test_ids = train_test_split(
    df_1mrg.index, #X, Y,
    test_size=0.15,
    random_state = 123,
    shuffle = True,
    stratify=Y
)

# print("Train:")
# print(f"\tX: {X_train.shape}; Y: {y_train.shape}(avg: {y_train.mean()})")
# print("Test:")
# print(f"\tX: {X_test.shape}; Y: {y_test.shape}(avg: {y_test.mean()})")

X_train = df_1mrg.loc[train_ids][FEATURES]
y_train = df_1mrg.loc[train_ids][['Target']]
X_test = df_1mrg.loc[test_ids][FEATURES]
y_test = df_1mrg.loc[test_ids][['Target']]

X_test

X_train[FEATURES], scaler_st = transform_get_fitted_StandardScaler(X_train, FEATURES)
df_X_train = X_train[FEATURES]
X_test[FEATURES] = scaler_st.transform(X_test[FEATURES])
df_X_test = X_test[FEATURES]

X_test

X_train = X_train.values
X_test = X_test.values
y_train = y_train.values.reshape(-1)
y_test = y_test.values.reshape(-1)

"""## Logistic Regression

### Variant 1 - Base (on 'df_1mrg' dataset)
"""

LABELS = { 0: "Did not take", 1: "Took"}

from sklearn.linear_model import LogisticRegression
params = {
    'max_iter': 50,
    # 'class_weight': 'balanced', # {0: 0.2, 1: 3.8} - manual weighting
    # 'penalty': 'l1',
    'solver': 'saga',
    'random_state': 42,
}
logistic = LogisticRegression(verbose=10, n_jobs=1, **params)
logistic = logistic.fit(X_train, y_train)

from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve
threshold = 0.5

Ytrue = y_test
Yprob = logistic.predict_proba(X_test)
Ypred = Yprob > threshold #Ypred = logistic.predict(X_test)

print(classification_report(Ytrue, np.argmax(Ypred, axis=1), digits=3, target_names=list(LABELS.values())))

import seaborn as sns
import matplotlib.pyplot as plt

# Creating four different sections in one figure for each class
fig, axs = plt.subplots(1, 2, figsize=(12, 8))
NUM_CLASSES = 2

# Probability distribution for each class
for i in range(NUM_CLASSES):
    ax = axs[i % 2]  # [i // 2, i % 2]
    sns.histplot(Yprob[:, i], bins=20, kde=True, ax=ax)
    ax.set_title(f'Class "{LABELS[i]}"')
    ax.set_xlabel('Predicted Probability')
    ax.set_ylabel('Frequency')
    # Setting the scale on the X-axis from 0 to 1
    ax.set_xlim(0, 1)

# Overall title
fig.suptitle(f'params={str(params)}', fontsize=16)
plt.tight_layout()
plt.show()

"""### Automatically tuning Hyperparameters
with GreadSearchCV
"""

Y.mean()

np.logspace(-1, 1, 10)

from sklearn.model_selection import GridSearchCV
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import QuantileTransformer, StandardScaler
from sklearn.linear_model import LogisticRegression
import numpy as np
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import make_scorer, accuracy_score, f1_score

model = LogisticRegression(max_iter=500, random_state=42, verbose=3, n_jobs=1)

# Defining the pipeline
pipeline = Pipeline([
    # ('standard_transform', StandardScaler()),
    # ('quantile_transform', QuantileTransformer(output_distribution='uniform')),
    ('model', model)
])
param_grid = {
    'model__C': np.logspace(0, 1, 10),  # Specify 'C' within the 'model' step of the pipeline
    'model__penalty': ['l1', 'l2'],
    'model__class_weight': [None, 'balanced', {0:0.85, 1:1}],
    'model__solver': ['saga', 'liblinear'],
}

scoring = {
    # 'f1_macro': 'f1_macro',
    'f1_w': 'f1_weighted',
    'AUC': 'roc_auc_ovr',
    'accuracy': make_scorer(accuracy_score),
}

# Creating a GridSearchCV object
grid_search = GridSearchCV(
    estimator=pipeline, # a pipeline with feature scaling
    # estimator=model, # normal model
    param_grid=param_grid,
    cv=5,
    scoring=scoring,
    refit='f1_w',  # Setting the metric for re-training the best model
    verbose=3,
    n_jobs=1
)

# Training using GridSearchCV
grid_search.fit(X_train, y_train)

# Best parameters and score
print("\nBest Parameters:", grid_search.best_params_)
print("Best score:", grid_search.best_score_)

"""#### Estimating best variant"""

best_model = grid_search.best_estimator_
display(best_model)

params = grid_search.best_params_
display(params)

from sklearn.linear_model import LogisticRegression
# params = {
#     'max_iter': 10,
#     # 'multi_class': 'ovr',
#     # 'class_weight': 'balanced', # {0: 0.2, 1: 0.8} - manual weighting
#     'penalty': 'l2',
#     'solver': 'liblinear',
#     'random_state': 42,
# }
# best_model.fit(X_train, y_train)

from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve
threshold = 0.5

Ytrue = y_test
Yprob = best_model.predict_proba(X_test)
Ypred = Yprob > threshold #logistic.predict(X_test)

Yprob[0:10]

LABELS = { 0: "Did not take", 1: "Took"}

import seaborn as sns
import matplotlib.pyplot as plt

# Creating four different sections in one figure for each class
fig, axs = plt.subplots(1, 2, figsize=(7, 5))
NUM_CLASSES = 2

# Probability distribution for each class
for i in range(NUM_CLASSES):
    ax = axs[i % 2] # [i // 2, i % 2]
    sns.histplot(Yprob[:, i], bins=20, kde=True, ax=ax)
    ax.set_title(f'Class {LABELS[i]}')
    ax.set_xlabel('Predicted probability')
    ax.set_ylabel('Frequency')
    # Setting the scale on the X-axis from 0 to 1
    ax.set_xlim(0, 1)

# Overall title
fig.suptitle(f'params={str(params)}', fontsize=16)
plt.tight_layout()
plt.show()

from sklearn.metrics import roc_auc_score
# micro ROC AUC
# roc_auc_micro = roc_auc_score(Ytrue, np.argmax(Yprob, axis=1), average='micro')
roc_auc_micro = roc_auc_score(Ytrue, np.argmax(Yprob, axis=1), average='micro')

# macro ROC AUC
roc_auc_macro = roc_auc_score(Ytrue, np.argmax(Yprob, axis=1), average='macro')

print("Micro ROC AUC:", roc_auc_micro)
print("Macro ROC AUC:", roc_auc_macro)

print(classification_report(Ytrue, np.argmax(Ypred, axis=1), digits=3, target_names=['0', '1']))

import seaborn as sns

# Confusion matrix
cm = confusion_matrix(Ytrue, np.argmax(Ypred, axis=1))

# Visualization
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.show()

_ = plot_CM(best_model, X_test, y_test, ['Did not take', 'Took'], figsize=[7,7])

metrics = plot_multiclass_roc(Ytrue.reshape(-1), Yprob, labels=['Did not take', 'Took'])

"""## RandomForestClassifier

### Variant 1 - Base (on 'df_1mrg' dataset)
"""

LABELS = { 1: "Took", 0: "Did not take"}

from sklearn.ensemble import RandomForestClassifier

# Creating a pipeline for the entire process - preprocessing and model training
model = Pipeline(steps=[
    ('classifier', RandomForestClassifier()),
])

params = {
    'n_estimators': 50,
    'max_features': 'log2',
    'max_depth': 8,
    'min_samples_split': 21,
    'min_samples_leaf': 5,
    'bootstrap': True,
}
model = RandomForestClassifier(verbose=5, n_jobs=1, **params)
model = model.fit(X_train, y_train)

from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve
threshold = 0.5

Ytrue = y_test
Yprob = model.predict_proba(X_test)
Ypred = Yprob > threshold #Ypred = logistic.predict(X_test)

print(classification_report(Ytrue, np.argmax(Ypred, axis=1), digits=3, target_names=list(LABELS.values())))

import seaborn as sns
import matplotlib.pyplot as plt

# Creating four different sections in one figure for each class
fig, axs = plt.subplots(1, 2, figsize=(12, 8))
NUM_CLASSES = 2

# Probability distribution for each class
for i in range(NUM_CLASSES):
    ax = axs[i % 2] # [i // 2, i % 2]
    sns.histplot(Yprob[:, i], bins=20, kde=True, ax=ax)
    ax.set_title(f'Class "{LABELS[i]}"')
    ax.set_xlabel('Predicted Probability')
    ax.set_ylabel('Frequency')
    # Setting the scale on the X-axis from 0 to 1
    ax.set_xlim(0, 1)

# Overall title
fig.suptitle(f'params={str(params)}', fontsize=16)
plt.tight_layout()
plt.show()

"""### Automatically tuning Hyperparameters
with GreadSearchCV
"""

from sklearn.model_selection import GridSearchCV
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import QuantileTransformer, StandardScaler
import numpy as np
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import make_scorer, accuracy_score, f1_score
from sklearn.ensemble import RandomForestClassifier


# Creating a pipeline
pipeline = Pipeline([
    # ('standard_transform', StandardScaler()),
    # ('quantile_transform', QuantileTransformer(output_distribution='uniform')),
    ('model', RandomForestClassifier())
])
param_grid = {
    'model__n_estimators': [75, 100, 150],
    'model__max_features': ['sqrt', 'log2'],
    'model__max_depth': [None], #[5, 8, 13],
    'model__min_samples_split': [21, 34, 45],
    'model__min_samples_leaf': [3, 5, 8],
    'model__bootstrap': [True],
    'model__class_weight': [None, 'balanced']
}
scoring = {
    'f1_w': 'f1_weighted',
    'AUC': 'roc_auc',
    'accuracy': make_scorer(accuracy_score),
}

# Creating object GridSearchCV
grid_search = GridSearchCV(
    estimator=pipeline, # a pipeline with feature scaling
    param_grid=param_grid,
    cv=5,
    scoring=scoring,
    refit='f1_w',  # Setting the metric for re-training the best model
    verbose=3,
    n_jobs=1
)

# Training with GridSearchCV
grid_search.fit(X_train, y_train.reshape(-1))

# Best parameters and best score
print("\nBest Parameters:", grid_search.best_params_)
print("Best score:", grid_search.best_score_)

"""#### Estimating best variant"""

best_model = grid_search.best_estimator_
display(best_model)

params = grid_search.best_params_
display(params)

from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve
threshold = 0.5

Ytrue = y_test
Yprob = best_model.predict_proba(X_test)
Ypred = Yprob > threshold #logistic.predict(X_test)

Yprob[0:10]

LABELS = { 0: "Did not take", 1: "Took"}

import seaborn as sns
import matplotlib.pyplot as plt

# Creating four different sections in one figure for each class
fig, axs = plt.subplots(1, 2, figsize=(7, 5))
NUM_CLASSES = 2

# Probability distribution for each class
for i in range(NUM_CLASSES):
    ax = axs[i % 2] # [i // 2, i % 2]
    sns.histplot(Yprob[:, i], bins=20, kde=True, ax=ax)
    ax.set_title(f'Class {LABELS[i]}')
    ax.set_xlabel('Predicted probability')
    ax.set_ylabel('Frequency')
    # Setting the scale on the X-axis from 0 to 1
    ax.set_xlim(0, 1)

# Overall title
fig.suptitle(f'params={str(params)}', fontsize=16)
plt.tight_layout()
plt.show()

from sklearn.metrics import roc_auc_score
# Micro  ROC AUC
# roc_auc_micro = roc_auc_score(Ytrue, np.argmax(Yprob, axis=1), average='micro')
roc_auc_micro = roc_auc_score(Ytrue, np.argmax(Yprob, axis=1), average='micro')

# Macro  ROC AUC
roc_auc_macro = roc_auc_score(Ytrue, np.argmax(Yprob, axis=1), average='macro')

print("Micro  ROC AUC:", roc_auc_micro)
print("Macro  ROC AUC:", roc_auc_macro)

print(classification_report(Ytrue, np.argmax(Ypred, axis=1), digits=3, target_names=['0', '1']))

import seaborn as sns

# Calculating confusion matrix
cm = confusion_matrix(Ytrue, np.argmax(Ypred, axis=1))

# Visualize
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.show()

_ = plot_CM(best_model, X_test, y_test, ['Did not take', 'Took'], figsize=[7,7])

metrics = plot_multiclass_roc(Ytrue.reshape(-1), Yprob, labels=['Did not take', 'Took'])

"""## CatBoostClassifier

### Variant 1 - Base (on 'df_1mrg' dataset)
"""

from catboost import CatBoostClassifier, Pool

# Data preparation
pool_train = Pool(X_train, y_train)
pool_test = Pool(X_test, y_test)

# Model initialization
model = CatBoostClassifier(eval_metric='AUC:hints=skip_train~false', random_seed=42, loss_function='Logloss', verbose=10)

# Defining the parameter grid for the search, including iterations
param_grid = {
    'iterations': [1500],
    'depth': [4, 6, 8],
    'learning_rate': [0.04, 0.1, 0.25],
    'l2_leaf_reg': [0.5, 1, 2, 3, 5, 8]
}

# Search start
grid_search_result = model.grid_search(param_grid, pool_train)

# REsult analysis
print(grid_search_result['cv_results'])

grid_search_result['params']

from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve
threshold = 0.5

Ytrue = y_test
Yprob = model.predict_proba(X_test)
Ypred = Yprob > threshold #Ypred = logistic.predict(X_test)

print(classification_report(Ytrue, np.argmax(Ypred, axis=1), digits=3, target_names=list(LABELS.values())))

import seaborn as sns
import matplotlib.pyplot as plt

# Creating four different sections in one figure for each class
fig, axs = plt.subplots(1, 2, figsize=(12, 8))
NUM_CLASSES = 2

# Probability distribution for each class
for i in range(NUM_CLASSES):
    ax = axs[i % 2] # [i // 2, i % 2]
    sns.histplot(Yprob[:, i], bins=20, kde=True, ax=ax)
    ax.set_title(f'Class "{LABELS[i]}"')
    ax.set_xlabel('Predicted Probability')
    ax.set_ylabel('Frequency')
    # Setting the scale on the X-axis from 0 to 1
    ax.set_xlim(0, 1)

# Overall title
fig.suptitle(f'params={str(params)}', fontsize=16)
plt.tight_layout()
plt.show()

"""# Reducing features count

## PCA

### Transforming the dataset
"""

print(FEATURES)

len(FEATURES)

from sklearn.decomposition import PCA

analyzerPCA = PCA()
analyzerPCA.fit(df_X_train[FEATURES])

import plotly.graph_objects as go

# Obtaining and analyzing the explained variance of each component
explained_var_ratio = analyzerPCA.explained_variance_ratio_

# Cumulative sum of explained variance
cumulative_var_ratio = np.cumsum(explained_var_ratio)

# Building an interactive plot
fig = go.Figure()

fig.add_trace(go.Scatter(y=cumulative_var_ratio, mode='lines+markers', name='Cumulative Variance'))
fig.update_layout(title='Cumulative Explained Variance by PCA Components',
                  xaxis_title='Number of Components',
                  yaxis_title='Cumulative Explained Variance',
                  margin=dict(l=0, r=0, t=30, b=0))
fig.show()

# Choosing the number of components
# For example, determining the number of components to explain 95% variance
TH = 0.98
num_components_reduced = np.where(cumulative_var_ratio >= TH)[0][0] + 1
print(f"Number of components to explain {TH * 100.0}% variance: {num_components_reduced}")

from sklearn.decomposition import PCA

reducerPCA = PCA(n_components=num_components_reduced)
X_train_reduced = reducerPCA.fit_transform(df_X_train[FEATURES])
X_test_reduced = reducerPCA.transform(df_X_test[FEATURES])
print(X_train_reduced.shape)
print(X_test_reduced.shape)

"""#### Variant 1 - LogisticRegression Base (on 'df_1mrg' dataset)"""

LABELS = { 0: "Did not take", 1: "Took"}

from sklearn.linear_model import LogisticRegression
params = {
    'max_iter': 50,
    # 'class_weight': 'balanced', # {0: 0.2, 1: 3.8} - manual weighting
    # 'penalty': 'l1',
    'solver': 'saga',
    'random_state': 42,
}
logistic = LogisticRegression(verbose=10, n_jobs=1, **params)
logistic = logistic.fit(X_train_reduced, y_train)

from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve
threshold = 0.5

Ytrue = y_test
Yprob = logistic.predict_proba(X_test_reduced)
Ypred = Yprob > threshold #Ypred = logistic.predict(X_test)

from sklearn.metrics import roc_auc_score
# Micro  ROC AUC
# roc_auc_micro = roc_auc_score(Ytrue, np.argmax(Yprob, axis=1), average='micro')
roc_auc_micro = roc_auc_score(Ytrue, np.argmax(Yprob, axis=1), average='micro')

# Macro  ROC AUC
roc_auc_macro = roc_auc_score(Ytrue, np.argmax(Yprob, axis=1), average='macro')

print("Micro  ROC AUC:", roc_auc_micro)
print("Macro  ROC AUC:", roc_auc_macro)

print(classification_report(Ytrue, np.argmax(Ypred, axis=1), digits=3, target_names=list(LABELS.values())))

_ = plot_CM(logistic, X_test_reduced, y_test, ['Did not take', 'Took'], figsize=[7,7])

import seaborn as sns
import matplotlib.pyplot as plt

# Creating four different sections in one figure for each class
fig, axs = plt.subplots(1, 2, figsize=(12, 8))
NUM_CLASSES = 2

# Probability distribution for each class
for i in range(NUM_CLASSES):
    ax = axs[i % 2] # [i // 2, i % 2]
    sns.histplot(Yprob[:, i], bins=20, kde=True, ax=ax)
    ax.set_title(f'Class "{LABELS[i]}"')
    ax.set_xlabel('Predicted Probability')
    ax.set_ylabel('Frequency')
    # Setting the scale on the X-axis from 0 to 1
    ax.set_xlim(0, 1)

# Overall title
fig.suptitle(f'params={str(params)}', fontsize=16)
plt.tight_layout()
plt.show()

metrics = plot_multiclass_roc(Ytrue.reshape(-1), Yprob, labels=['Did not take', 'Took'])

"""#### Variant 2 - CatBoostClassifier (grid_search)"""

from catboost import CatBoostClassifier, Pool

# Data preparation
pool_train = Pool(X_train_reduced, y_train)
pool_test = Pool(X_test_reduced, y_test)

# Model initialization
model = CatBoostClassifier(
    eval_metric='AUC:hints=skip_train~false',
    random_seed=42,
    loss_function='Logloss',
    verbose=10,
    early_stopping_rounds=300
)

# Defining the parameter grid for the search, including iterations
param_grid = {
    'iterations': [1500],
    'depth': [4, 6, 8],
    'learning_rate': [0.04, 0.1, 0.25],
    'l2_leaf_reg': [0.5, 1, 2, 3, 5, 8]
}

# Search start
grid_search_result = model.grid_search(param_grid, pool_train)

# Result analysis
print(grid_search_result['cv_results'])

params = grid_search_result['params']
display(params)

from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve
threshold = 0.5

Ytrue = y_test
Yprob = model.predict_proba(X_test_reduced)
Ypred = Yprob > threshold #Ypred = logistic.predict(X_test)

print(classification_report(Ytrue, np.argmax(Ypred, axis=1), digits=3, target_names=list(LABELS.values())))

_ = plot_CM(model, X_test_reduced, y_test, ['Did not take', 'Took'], figsize=[7,7])

metrics = plot_multiclass_roc(Ytrue.reshape(-1), Yprob, labels=['Did not take', 'Took'])

import seaborn as sns
import matplotlib.pyplot as plt

# Creating four different sections in one figure for each class
fig, axs = plt.subplots(1, 2, figsize=(12, 8))
NUM_CLASSES = 2

# Probability distribution for each class
for i in range(NUM_CLASSES):
    ax = axs[i % 2] # [i // 2, i % 2]
    sns.histplot(Yprob[:, i], bins=20, kde=True, ax=ax)
    ax.set_title(f'Class "{LABELS[i]}"')
    ax.set_xlabel('Predicted Probability')
    ax.set_ylabel('Frequency')
    # Setting the scale on the X-axis from 0 to 1
    ax.set_xlim(0, 1)

# Overall title
fig.suptitle(f'params={str(params)}', fontsize=16)
plt.tight_layout()
plt.show()

"""## Isomap"""

from sklearn.manifold import Isomap
import numpy as np
import plotly.graph_objects as go

NEIGHBORS = 25
# Applying Isomap for different number of components
n_components_list = range(2, len(FEATURES))  # For example, from 2 to 20 components
errors = []

for n in n_components_list:
    isomap = Isomap(n_components=n, n_neighbors=NEIGHBORS)
    isomap.fit(df_X_train[FEATURES])
    errors.append(isomap.reconstruction_error())

# Plotting the reconstruction errors for different number of components
fig = go.Figure(data=go.Scatter(x=list(n_components_list), y=errors, mode='lines+markers'))
fig.update_layout(title=f'Isomap Reconstruction Error as a Function of Number of Components (with {NEIGHBORS} neighbors)',
                  xaxis_title='Number of Components',
                  yaxis_title='Reconstruction Error',
                  margin=dict(l=0, r=0, t=30, b=0))
fig.show()

"""### Transforming the dataset"""

print(FEATURES)

len(FEATURES)

num_components_reduced = 70
NEIGHBORS = 25

from sklearn.manifold import Isomap

isomap = Isomap(n_components=num_components_reduced, n_neighbors=NEIGHBORS)
X_train_reduced = isomap.fit_transform(df_X_train[FEATURES])
X_test_reduced = isomap.transform(df_X_test[FEATURES])
print(X_train_reduced.shape)
print(X_test_reduced.shape)

"""#### Variant 1 - LogisticRegression Base (on 'df_1mrg' dataset)"""

LABELS = { 0: "Did not take", 1: "Took"}

from sklearn.linear_model import LogisticRegression
params = {
    'max_iter': 50,
    # 'class_weight': 'balanced', # {0: 0.2, 1: 3.8} - manual weighting
    # 'penalty': 'l1',
    'solver': 'saga',
    'random_state': 42,
}
logistic = LogisticRegression(verbose=10, n_jobs=1, **params)
logistic = logistic.fit(X_train_reduced, y_train)

from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve
threshold = 0.5

Ytrue = y_test
Yprob = logistic.predict_proba(X_test_reduced)
Ypred = Yprob > threshold #Ypred = logistic.predict(X_test)

from sklearn.metrics import roc_auc_score
# Micro  ROC AUC
# roc_auc_micro = roc_auc_score(Ytrue, np.argmax(Yprob, axis=1), average='micro')
roc_auc_micro = roc_auc_score(Ytrue, np.argmax(Yprob, axis=1), average='micro')

# Macro  ROC AUC
roc_auc_macro = roc_auc_score(Ytrue, np.argmax(Yprob, axis=1), average='macro')

print("Micro  ROC AUC:", roc_auc_micro)
print("Macro  ROC AUC:", roc_auc_macro)

print(classification_report(Ytrue, np.argmax(Ypred, axis=1), digits=3, target_names=list(LABELS.values())))

_ = plot_CM(logistic, X_test_reduced, y_test, ['Did not take', 'Took'], figsize=[7,7])

import seaborn as sns
import matplotlib.pyplot as plt

# Creating four different sections in one figure for each class
fig, axs = plt.subplots(1, 2, figsize=(12, 8))
NUM_CLASSES = 2

# Probability distribution for each class
for i in range(NUM_CLASSES):
    ax = axs[i % 2] # [i // 2, i % 2]
    sns.histplot(Yprob[:, i], bins=20, kde=True, ax=ax)
    ax.set_title(f'Class "{LABELS[i]}"')
    ax.set_xlabel('Predicted Probability')
    ax.set_ylabel('Frequency')
    # Setting the scale on the X-axis from 0 to 1
    ax.set_xlim(0, 1)

# Overall title
fig.suptitle(f'params={str(params)}', fontsize=16)
plt.tight_layout()
plt.show()

metrics = plot_multiclass_roc(Ytrue.reshape(-1), Yprob, labels=['Did not take', 'Took'])

"""#### Variant 2 - CatBoostClassifier (grid_search)"""

from catboost import CatBoostClassifier, Pool

# Data preparation
pool_train = Pool(X_train_reduced, y_train)
pool_test = Pool(X_test_reduced, y_test)

# Model initialization
model = CatBoostClassifier(
    eval_metric='AUC:hints=skip_train~false',
    random_seed=42,
    loss_function='Logloss',
    verbose=10,
    early_stopping_rounds=300
)

# Defining the parameter grid for the search, including iterations
param_grid = {
    'iterations': [1500],
    'depth': [4, 6, 8],
    'learning_rate': [0.04, 0.1, 0.25],
    'l2_leaf_reg': [0.5, 1, 2, 3, 5, 8]
}

# Search start
grid_search_result = model.grid_search(param_grid, pool_train)

# Results analysis
print(grid_search_result['cv_results'])

grid_search_result['params']

from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve
threshold = 0.5

Ytrue = y_test
Yprob = model.predict_proba(X_test_reduced)
Ypred = Yprob > threshold #Ypred = logistic.predict(X_test)

print(classification_report(Ytrue, np.argmax(Ypred, axis=1), digits=3, target_names=list(LABELS.values())))

_ = plot_CM(model, X_test_reduced, y_test, ['Did not take', 'Took'], figsize=[7,7])

metrics = plot_multiclass_roc(Ytrue.reshape(-1), Yprob, labels=['Did not take', 'Took'])

import seaborn as sns
import matplotlib.pyplot as plt

# Creating four different sections in one figure for each class
fig, axs = plt.subplots(1, 2, figsize=(12, 8))
NUM_CLASSES = 2

# Probability distribution for each class
for i in range(NUM_CLASSES):
    ax = axs[i % 2] # [i // 2, i % 2]
    sns.histplot(Yprob[:, i], bins=20, kde=True, ax=ax)
    ax.set_title(f'Class "{LABELS[i]}"')
    ax.set_xlabel('Predicted Probability')
    ax.set_ylabel('Frequency')
    # Setting the scale on the X-axis from 0 to 1
    ax.set_xlim(0, 1)

# Overall title
fig.suptitle(f'params={str(params)}', fontsize=16)
plt.tight_layout()
plt.show()

"""As we can see here, the best results, with accuracy 0.88 gave CatBoost. Then we tried PCA and Isomap, but both of these decreased accuracy. Seems for our dataset we do not need to decrease quantity of features."""